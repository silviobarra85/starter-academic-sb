@article{PODDA2022101816,
title = {Fully-automated deep learning pipeline for segmentation and classification of breast ultrasound images},
journal = {Journal of Computational Science},
volume = {63},
pages = {101816},
year = {2022},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2022.101816},
url = {https://www.sciencedirect.com/science/article/pii/S187775032200182X},
author = {Alessandro Sebastian Podda and Riccardo Balia and Silvio Barra and Salvatore Carta and Gianni Fenu and Leonardo Piano},
keywords = {Breast cancer diagnosis, Ultrasound images, Convolutional Neural Networks},
abstract = {Breast cancer is the most prevalent type of cancer among the female world population. Its early detection has a crucial role in enhancing the effectiveness of treatments, as well as reducing serious complications and deaths. Ultrasound imaging represents a standard diagnostic technique for this purpose, due to its low invasiveness and cost. However, as this technique is susceptible to a certain degree of uncertainty, computer-aided solutions have been proposed in recent years to reduce the operator workload and improve the accuracy of diagnoses. Following this trend, the present study aims to design and propose a fully-automated and multi-layer pipeline for the segmentation and classification of breast lesions associated with cancer risk, from ultrasound images. To achieve this goal, we first evaluate and compare the performance of several Convolutional Neural Network (CNN) architectures in tackling the above tasks. Then, we combine the performance of such networks through specialized ensembles, to better discriminate among heterogeneous cases. Lastly, we present a novel step of cyclic mutual optimization that exploits the intermediate results of the classification step to improve the segmentation outcome and vice versa, in an iterative manner. Experimental findings obtained on public datasets show the superiority of the ensemble methods over the individual networks. Moreover, with a Dice coefficient of ∼82% in the segmentation task and an accuracy of ∼91% in the classification task, our best configuration also shows to be competitive with respect to the state-of-the-art.}
}